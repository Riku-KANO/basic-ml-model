{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORKE5KPJrVG+85wfpB6zrZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riku-KANO/basic-ml-model/blob/main/dl/generator/simple_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simple GAN"
      ],
      "metadata": {
        "id": "-puBekywOA-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 読み込み"
      ],
      "metadata": {
        "id": "O7ERa8PUOER3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import yaml\n",
        "import pickle\n",
        "import warnings\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "try:\n",
        "    import datasets\n",
        "except ImportError:\n",
        "    !pip install -q datasets\n",
        "    import datasets"
      ],
      "metadata": {
        "id": "EeVSslURJUbV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GANの実装"
      ],
      "metadata": {
        "id": "J7REssokOGrF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1YC3ocYI9Fs"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3, 1, 1)\n",
        "        self.conv7 = nn.Conv2d(1024, 1, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv4(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv5(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv6(x), 0.2)\n",
        "        x = self.conv7(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_dataset = datasets.MNIST('~/pytorch/MNIST_data/', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.MNIST('~/pytorch/MNIST_data/', train=False,transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "XTuctNVpJwdO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}